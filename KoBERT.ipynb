{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gluonnlp pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece==0.1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27560/1911866731.py:3: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np,'bool'):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if not hasattr(np,'bool'):\n",
    "    np.bool = bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/azureuser/Desktop/kr/.cache/kobert_v1.zip\n",
      "using cached model. /home/azureuser/Desktop/kr/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/azureuser/Desktop/kr/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/anaconda3/envs/kobert3/lib/python3.8/site-packages/transformers/modeling_utils.py:1211: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from kobert.utils import get_tokenizer\n",
    "\n",
    "# KoBert 모델과 토크나이저 불러오기\n",
    "model, vocab = get_pytorch_kobert_model()\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "\n",
    "# transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import BertModel\n",
    "\n",
    "# GPU 사용\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터셋 토큰화하기\n",
    "# 각 데이터가 BERT 모델의 입력으로 들어갈 수 있도록 tokenization, int encoding, padding 등을 해주는 코드\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len, pad, pair):\n",
    "\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair\n",
    "        )\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 16\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/15 09:17:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/15 09:17:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# SparkSession 생성\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder.appName(\"Spark로 HDFS CSV 로드\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://127.0.0.1:9000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data = spark.read.csv('hdfs://localhost:9000/hdfs_folder/KorCCViD.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|                              _c0|  _c1|\n",
      "+---------------------------------+-----+\n",
      "|                       Transcript|Label|\n",
      "|   사람 전라도 광주 태장 42 고...|    1|\n",
      "| 서울 중앙지 숫자 인데 개인 정...|    1|\n",
      "|    여기 끝내 2005 김창호 도용...|    1|\n",
      "| 웨딩 으로 원래 그대로 근데 그...|    0|\n",
      "| 답답 지금 선생 본인 래요 자기...|    1|\n",
      "| 서울 중앙 지검 김진호 수사관 ...|    1|\n",
      "|여보세요 들어왔 습니까 수고 십...|    1|\n",
      "| 우리 호텔 인데 불구 너무 더라...|    0|\n",
      "| 그래 그서 경우 처음 아니 했잖...|    0|\n",
      "| 우선 사건 연결 현미 때문 검찰...|    1|\n",
      "|신한은행 경우 어쩌면 지금 마지...|    1|\n",
      "| 누구 김강호 구요 서울 출신 입...|    1|\n",
      "| 오래 동차 라고 동시 봐야 거든...|    0|\n",
      "| 그래도 뭔가 그런 기회 라도 으...|    0|\n",
      "| 확인 농협 하나 통장 확인 경기...|    1|\n",
      "| 대로 그래 카운터 아니 무슨 건...|    0|\n",
      "|여보세요 방법 국민은행 고객 적...|    1|\n",
      "| 안녕 세요 씨티 캐피탈 씨티 캐...|    1|\n",
      "| 초등 학교 학년 학년 친한 친구...|    0|\n",
      "+---------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transcript</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _c0    _c1\n",
       "0                                         Transcript  Label\n",
       "1  사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...      1\n",
       "2  서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...      1\n",
       "3  여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...      1\n",
       "4  웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 0 행 제거\n",
    "df.drop([0], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _c0 _c1\n",
       "1  사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...   1\n",
       "2  서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...   1\n",
       "3  여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...   1\n",
       "4  웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...   0\n",
       "5  답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...   1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 초기화\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _c0 _c1\n",
       "0  사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...   1\n",
       "1  서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...   1\n",
       "2  여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...   1\n",
       "3  웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...   0\n",
       "4  답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...   1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column명 변경\n",
    "df.columns = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  사람 전라도 광주 태장 42 고요 명동 에서 10 정도 근무 했었 200 보여 그리...     1\n",
       "1  서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 습니다 혹시 김용진 라...     1\n",
       "2  여기 끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외...     1\n",
       "3  웨딩 으로 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치...     0\n",
       "4  답답 지금 선생 본인 래요 자기 성함 아니 에요 아니 통해서 통화 어요 답답 십니다...     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_clean(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '[a-zA-Z]'    # 알파벳 제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 텍스트 제거\n",
    "for i in range(len(df)):\n",
    "    df['text'][i] = text_clean(df['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자는 의미가 있다고 판단하여 제거하지 않았다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어(stopwords) 처리\n",
    "# 불용어 사전 불러오기\n",
    "# sw = spark.read.text('hdfs://localhost:9000/hdfs_folder/stopwords-ko.txt')\n",
    "sw_df = pd.read_csv('/home/azureuser/Desktop/kr/stopwords-ko.txt', names=['value'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw_df = sw.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가까스로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가령</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>각</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>각각</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  value\n",
       "0     가\n",
       "1  가까스로\n",
       "2    가령\n",
       "3     각\n",
       "4    각각"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "for i in range(len(sw_df)):\n",
    "    stop_words.append(sw_df['value'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['가',\n",
       " '가까스로',\n",
       " '가령',\n",
       " '각',\n",
       " '각각',\n",
       " '각자',\n",
       " '각종',\n",
       " '갖고말하자면',\n",
       " '같다',\n",
       " '같이',\n",
       " '개의치않고',\n",
       " '거니와',\n",
       " '거바',\n",
       " '거의',\n",
       " '것',\n",
       " '것과 같이',\n",
       " '것들',\n",
       " '게다가',\n",
       " '게우다',\n",
       " '겨우',\n",
       " '견지에서',\n",
       " '결과에 이르다',\n",
       " '결국',\n",
       " '결론을 낼 수 있다',\n",
       " '겸사겸사',\n",
       " '고려하면',\n",
       " '고로',\n",
       " '곧',\n",
       " '공동으로',\n",
       " '과',\n",
       " '과연',\n",
       " '관계가 있다',\n",
       " '관계없이',\n",
       " '관련이 있다',\n",
       " '관하여',\n",
       " '관한',\n",
       " '관해서는',\n",
       " '구',\n",
       " '구체적으로',\n",
       " '구토하다',\n",
       " '그',\n",
       " '그들',\n",
       " '그때',\n",
       " '그래',\n",
       " '그래도',\n",
       " '그래서',\n",
       " '그러나',\n",
       " '그러니',\n",
       " '그러니까',\n",
       " '그러면',\n",
       " '그러므로',\n",
       " '그러한즉',\n",
       " '그런 까닭에',\n",
       " '그런데',\n",
       " '그런즉',\n",
       " '그럼',\n",
       " '그럼에도 불구하고',\n",
       " '그렇게 함으로써',\n",
       " '그렇지',\n",
       " '그렇지 않다면',\n",
       " '그렇지 않으면',\n",
       " '그렇지만',\n",
       " '그렇지않으면',\n",
       " '그리고',\n",
       " '그리하여',\n",
       " '그만이다',\n",
       " '그에 따르는',\n",
       " '그위에',\n",
       " '그저',\n",
       " '그중에서',\n",
       " '그치지 않다',\n",
       " '근거로',\n",
       " '근거하여',\n",
       " '기대여',\n",
       " '기점으로',\n",
       " '기준으로',\n",
       " '기타',\n",
       " '까닭으로',\n",
       " '까악',\n",
       " '까지',\n",
       " '까지 미치다',\n",
       " '까지도',\n",
       " '꽈당',\n",
       " '끙끙',\n",
       " '끼익',\n",
       " '나',\n",
       " '나머지는',\n",
       " '남들',\n",
       " '남짓',\n",
       " '너',\n",
       " '너희',\n",
       " '너희들',\n",
       " '네',\n",
       " '넷',\n",
       " '년',\n",
       " '논하지 않다',\n",
       " '놀라다',\n",
       " '누가 알겠는가',\n",
       " '누구',\n",
       " '다른',\n",
       " '다른 방면으로',\n",
       " '다만',\n",
       " '다섯',\n",
       " '다소',\n",
       " '다수',\n",
       " '다시 말하자면',\n",
       " '다시말하면',\n",
       " '다음',\n",
       " '다음에',\n",
       " '다음으로',\n",
       " '단지',\n",
       " '답다',\n",
       " '당신',\n",
       " '당장',\n",
       " '대로 하다',\n",
       " '대하면',\n",
       " '대하여',\n",
       " '대해 말하자면',\n",
       " '대해서',\n",
       " '댕그',\n",
       " '더구나',\n",
       " '더군다나',\n",
       " '더라도',\n",
       " '더불어',\n",
       " '더욱더',\n",
       " '더욱이는',\n",
       " '도달하다',\n",
       " '도착하다',\n",
       " '동시에',\n",
       " '동안',\n",
       " '된바에야',\n",
       " '된이상',\n",
       " '두번째로',\n",
       " '둘',\n",
       " '둥둥',\n",
       " '뒤따라',\n",
       " '뒤이어',\n",
       " '든간에',\n",
       " '들',\n",
       " '등',\n",
       " '등등',\n",
       " '딩동',\n",
       " '따라',\n",
       " '따라서',\n",
       " '따위',\n",
       " '따지지 않다',\n",
       " '딱',\n",
       " '때',\n",
       " '때가 되어',\n",
       " '때문에',\n",
       " '또',\n",
       " '또한',\n",
       " '뚝뚝',\n",
       " '라 해도',\n",
       " '령',\n",
       " '로',\n",
       " '로 인하여',\n",
       " '로부터',\n",
       " '로써',\n",
       " '륙',\n",
       " '를',\n",
       " '마음대로',\n",
       " '마저',\n",
       " '마저도',\n",
       " '마치',\n",
       " '막론하고',\n",
       " '만 못하다',\n",
       " '만약',\n",
       " '만약에',\n",
       " '만은 아니다',\n",
       " '만이 아니다',\n",
       " '만일',\n",
       " '만큼',\n",
       " '말하자면',\n",
       " '말할것도 없고',\n",
       " '매',\n",
       " '매번',\n",
       " '메쓰겁다',\n",
       " '몇',\n",
       " '모',\n",
       " '모두',\n",
       " '무렵',\n",
       " '무릎쓰고',\n",
       " '무슨',\n",
       " '무엇',\n",
       " '무엇때문에',\n",
       " '물론',\n",
       " '및',\n",
       " '바꾸어말하면',\n",
       " '바꾸어말하자면',\n",
       " '바꾸어서 말하면',\n",
       " '바꾸어서 한다면',\n",
       " '바꿔 말하면',\n",
       " '바로',\n",
       " '바와같이',\n",
       " '밖에 안된다',\n",
       " '반대로',\n",
       " '반대로 말하자면',\n",
       " '반드시',\n",
       " '버금',\n",
       " '보는데서',\n",
       " '보다더',\n",
       " '보드득',\n",
       " '본대로',\n",
       " '봐',\n",
       " '봐라',\n",
       " '부류의 사람들',\n",
       " '부터',\n",
       " '불구하고',\n",
       " '불문하고',\n",
       " '붕붕',\n",
       " '비걱거리다',\n",
       " '비교적',\n",
       " '비길수 없다',\n",
       " '비로소',\n",
       " '비록',\n",
       " '비슷하다',\n",
       " '비추어 보아',\n",
       " '비하면',\n",
       " '뿐만 아니라',\n",
       " '뿐만아니라',\n",
       " '뿐이다',\n",
       " '삐걱',\n",
       " '삐걱거리다',\n",
       " '사',\n",
       " '삼',\n",
       " '상대적으로 말하자면',\n",
       " '생각한대로',\n",
       " '설령',\n",
       " '설마',\n",
       " '설사',\n",
       " '셋',\n",
       " '소생',\n",
       " '소인',\n",
       " '솨',\n",
       " '쉿',\n",
       " '습니까',\n",
       " '습니다',\n",
       " '시각',\n",
       " '시간',\n",
       " '시작하여',\n",
       " '시초에',\n",
       " '시키다',\n",
       " '실로',\n",
       " '심지어',\n",
       " '아',\n",
       " '아니',\n",
       " '아니나다를가',\n",
       " '아니라면',\n",
       " '아니면',\n",
       " '아니었다면',\n",
       " '아래윗',\n",
       " '아무거나',\n",
       " '아무도',\n",
       " '아야',\n",
       " '아울러',\n",
       " '아이',\n",
       " '아이고',\n",
       " '아이구',\n",
       " '아이야',\n",
       " '아이쿠',\n",
       " '아하',\n",
       " '아홉',\n",
       " '안 그러면',\n",
       " '않기 위하여',\n",
       " '않기 위해서',\n",
       " '알 수 있다',\n",
       " '알았어',\n",
       " '앗',\n",
       " '앞에서',\n",
       " '앞의것',\n",
       " '야',\n",
       " '약간',\n",
       " '양자',\n",
       " '어',\n",
       " '어기여차',\n",
       " '어느',\n",
       " '어느 년도',\n",
       " '어느것',\n",
       " '어느곳',\n",
       " '어느때',\n",
       " '어느쪽',\n",
       " '어느해',\n",
       " '어디',\n",
       " '어때',\n",
       " '어떠한',\n",
       " '어떤',\n",
       " '어떤것',\n",
       " '어떤것들',\n",
       " '어떻게',\n",
       " '어떻해',\n",
       " '어이',\n",
       " '어째서',\n",
       " '어쨋든',\n",
       " '어쩔수 없다',\n",
       " '어찌',\n",
       " '어찌됏든',\n",
       " '어찌됏어',\n",
       " '어찌하든지',\n",
       " '어찌하여',\n",
       " '언제',\n",
       " '언젠가',\n",
       " '얼마',\n",
       " '얼마 안 되는 것',\n",
       " '얼마간',\n",
       " '얼마나',\n",
       " '얼마든지',\n",
       " '얼마만큼',\n",
       " '얼마큼',\n",
       " '엉엉',\n",
       " '에',\n",
       " '에 가서',\n",
       " '에 달려 있다',\n",
       " '에 대해',\n",
       " '에 있다',\n",
       " '에 한하다',\n",
       " '에게',\n",
       " '에서',\n",
       " '여',\n",
       " '여기',\n",
       " '여덟',\n",
       " '여러분',\n",
       " '여보시오',\n",
       " '여부',\n",
       " '여섯',\n",
       " '여전히',\n",
       " '여차',\n",
       " '연관되다',\n",
       " '연이서',\n",
       " '영',\n",
       " '영차',\n",
       " '옆사람',\n",
       " '예',\n",
       " '예를 들면',\n",
       " '예를 들자면',\n",
       " '예컨대',\n",
       " '예하면',\n",
       " '오',\n",
       " '오로지',\n",
       " '오르다',\n",
       " '오자마자',\n",
       " '오직',\n",
       " '오호',\n",
       " '오히려',\n",
       " '와',\n",
       " '와 같은 사람들',\n",
       " '와르르',\n",
       " '와아',\n",
       " '왜',\n",
       " '왜냐하면',\n",
       " '외에도',\n",
       " '요만큼',\n",
       " '요만한 것',\n",
       " '요만한걸',\n",
       " '요컨대',\n",
       " '우르르',\n",
       " '우리',\n",
       " '우리들',\n",
       " '우선',\n",
       " '우에 종합한것과같이',\n",
       " '운운',\n",
       " '월',\n",
       " '위에서 서술한바와같이',\n",
       " '위하여',\n",
       " '위해서',\n",
       " '윙윙',\n",
       " '육',\n",
       " '으로',\n",
       " '으로 인하여',\n",
       " '으로서',\n",
       " '으로써',\n",
       " '을',\n",
       " '응',\n",
       " '응당',\n",
       " '의',\n",
       " '의거하여',\n",
       " '의지하여',\n",
       " '의해',\n",
       " '의해되다',\n",
       " '의해서',\n",
       " '이',\n",
       " '이 되다',\n",
       " '이 때문에',\n",
       " '이 밖에',\n",
       " '이 외에',\n",
       " '이 정도의',\n",
       " '이것',\n",
       " '이곳',\n",
       " '이때',\n",
       " '이라면',\n",
       " '이래',\n",
       " '이러이러하다',\n",
       " '이러한',\n",
       " '이런',\n",
       " '이럴정도로',\n",
       " '이렇게 많은 것',\n",
       " '이렇게되면',\n",
       " '이렇게말하자면',\n",
       " '이렇구나',\n",
       " '이로 인하여',\n",
       " '이르기까지',\n",
       " '이리하여',\n",
       " '이만큼',\n",
       " '이번',\n",
       " '이봐',\n",
       " '이상',\n",
       " '이어서',\n",
       " '이었다',\n",
       " '이와 같다',\n",
       " '이와 같은',\n",
       " '이와 반대로',\n",
       " '이와같다면',\n",
       " '이외에도',\n",
       " '이용하여',\n",
       " '이유만으로',\n",
       " '이젠',\n",
       " '이지만',\n",
       " '이쪽',\n",
       " '이천구',\n",
       " '이천육',\n",
       " '이천칠',\n",
       " '이천팔',\n",
       " '인 듯하다',\n",
       " '인젠',\n",
       " '일',\n",
       " '일것이다',\n",
       " '일곱',\n",
       " '일단',\n",
       " '일때',\n",
       " '일반적으로',\n",
       " '일지라도',\n",
       " '임에 틀림없다',\n",
       " '입각하여',\n",
       " '입장에서',\n",
       " '잇따라',\n",
       " '있다',\n",
       " '자',\n",
       " '자기',\n",
       " '자기집',\n",
       " '자마자',\n",
       " '자신',\n",
       " '잠깐',\n",
       " '잠시',\n",
       " '저',\n",
       " '저것',\n",
       " '저것만큼',\n",
       " '저기',\n",
       " '저쪽',\n",
       " '저희',\n",
       " '전부',\n",
       " '전자',\n",
       " '전후',\n",
       " '점에서 보아',\n",
       " '정도에 이르다',\n",
       " '제',\n",
       " '제각기',\n",
       " '제외하고',\n",
       " '조금',\n",
       " '조차',\n",
       " '조차도',\n",
       " '졸졸',\n",
       " '좀',\n",
       " '좋아',\n",
       " '좍좍',\n",
       " '주룩주룩',\n",
       " '주저하지 않고',\n",
       " '줄은 몰랏다',\n",
       " '줄은모른다',\n",
       " '중에서',\n",
       " '중의하나',\n",
       " '즈음하여',\n",
       " '즉',\n",
       " '즉시',\n",
       " '지든지',\n",
       " '지만',\n",
       " '지말고',\n",
       " '진짜로',\n",
       " '쪽으로',\n",
       " '차라리',\n",
       " '참',\n",
       " '참나',\n",
       " '첫번째로',\n",
       " '쳇',\n",
       " '총적으로',\n",
       " '총적으로 말하면',\n",
       " '총적으로 보면',\n",
       " '칠',\n",
       " '콸콸',\n",
       " '쾅쾅',\n",
       " '쿵',\n",
       " '타다',\n",
       " '타인',\n",
       " '탕탕',\n",
       " '토하다',\n",
       " '통하여',\n",
       " '툭',\n",
       " '퉤',\n",
       " '틈타',\n",
       " '팍',\n",
       " '팔',\n",
       " '퍽',\n",
       " '펄렁',\n",
       " '하',\n",
       " '하게될것이다',\n",
       " '하게하다',\n",
       " '하겠는가',\n",
       " '하고 있다',\n",
       " '하고있었다',\n",
       " '하곤하였다',\n",
       " '하구나',\n",
       " '하기 때문에',\n",
       " '하기 위하여',\n",
       " '하기는한데',\n",
       " '하기만 하면',\n",
       " '하기보다는',\n",
       " '하기에',\n",
       " '하나',\n",
       " '하느니',\n",
       " '하는 김에',\n",
       " '하는 편이 낫다',\n",
       " '하는것도',\n",
       " '하는것만 못하다',\n",
       " '하는것이 낫다',\n",
       " '하는바',\n",
       " '하더라도',\n",
       " '하도다',\n",
       " '하도록시키다',\n",
       " '하도록하다',\n",
       " '하든지',\n",
       " '하려고하다',\n",
       " '하마터면',\n",
       " '하면 할수록',\n",
       " '하면된다',\n",
       " '하면서',\n",
       " '하물며',\n",
       " '하여금',\n",
       " '하여야',\n",
       " '하자마자',\n",
       " '하지 않는다면',\n",
       " '하지 않도록',\n",
       " '하지마',\n",
       " '하지마라',\n",
       " '하지만',\n",
       " '하하',\n",
       " '한 까닭에',\n",
       " '한 이유는',\n",
       " '한 후',\n",
       " '한다면',\n",
       " '한다면 몰라도',\n",
       " '한데',\n",
       " '한마디',\n",
       " '한적이있다',\n",
       " '한켠으로는',\n",
       " '한항목',\n",
       " '할 따름이다',\n",
       " '할 생각이다',\n",
       " '할 줄 안다',\n",
       " '할 지경이다',\n",
       " '할 힘이 있다',\n",
       " '할때',\n",
       " '할만하다',\n",
       " '할망정',\n",
       " '할뿐',\n",
       " '할수있다',\n",
       " '할수있어',\n",
       " '할줄알다',\n",
       " '할지라도',\n",
       " '할지언정',\n",
       " '함께',\n",
       " '해도된다',\n",
       " '해도좋다',\n",
       " '해봐요',\n",
       " '해서는 안된다',\n",
       " '해야한다',\n",
       " '해요',\n",
       " '했어요',\n",
       " '향하다',\n",
       " '향하여',\n",
       " '향해서',\n",
       " '허',\n",
       " '허걱',\n",
       " '허허',\n",
       " '헉',\n",
       " '헉헉',\n",
       " '헐떡헐떡',\n",
       " '형식으로 쓰여',\n",
       " '혹시',\n",
       " '혹은',\n",
       " '혼자',\n",
       " '훨씬',\n",
       " '휘익',\n",
       " '휴',\n",
       " '흐흐',\n",
       " '흥',\n",
       " '힘입어']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "for i in range(len(df)):\n",
    "    text = df['text'][i]\n",
    "    tokens = text.split(' ')\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    df['text'][i] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사람 전라도 광주 태장 42 고요 명동 10 정도 근무 했었 200 보여 인데 저녁...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 김용진 라고 으신 처음...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외계인 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>웨딩 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치 그렇...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>답답 지금 선생 본인 래요 성함 에요 통해서 통화 어요 답답 십니다 진짜 결과 아실...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  사람 전라도 광주 태장 42 고요 명동 10 정도 근무 했었 200 보여 인데 저녁...     1\n",
       "1  서울 중앙지 숫자 인데 개인 정보 유출 때문 확인 연락 드렸 김용진 라고 으신 처음...     1\n",
       "2  끝내 2005 김창호 도용 사건 고요 감당 서울 중앙 지검 지능 범죄 수사 외계인 ...     1\n",
       "3  웨딩 원래 그대로 근데 그것 요즘 웨딩 그런 추세 라고 수원 용인 그러 돌잔치 그렇...     0\n",
       "4  답답 지금 선생 본인 래요 성함 에요 통해서 통화 어요 답답 십니다 진짜 결과 아실...     1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for ques, label in zip(df['text'], df['label']):\n",
    "    temp = []\n",
    "    temp.append(ques)\n",
    "    temp.append(str(label))\n",
    "\n",
    "    data_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azureuser/Desktop/kr/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\n\\x0e\\n\\x05[UNK]\\x15\\x00\\x00\\x00\\x00\\x18\\x02\\n\\x0e\\n\\x05[PAD]\\x15\\x00\\x00\\x00\\x00\\x18\\x04\\n\\x0e\\n\\x05[CLS]\\x15\\x00\\x00\\x00\\x00\\x18\\x04\\n\\x0e\\n\\x05[SEP]\\x15\\x00\\x00\\x00\\x00\\x18\\x04\\n\\x0f\\n\\x06[MASK]\\x15\\x00\\x00\\x00\\x00\\x18\\x04\\n\\x08\\n\\x01!\\x15+\\xde\\x03\\xc1\\n\\t\\n\\x02!'\\x15\\x93\\x05\"\n"
     ]
    }
   ],
   "source": [
    "# tokenizer의 encoding 방식 확인\n",
    "with open(tokenizer, \"rb\") as f:\n",
    "    raw_data = f.read()\n",
    "    print(raw_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTF-8이 아닌 binary 형식이기 때문에 UTF-8 형식으로 변환\n",
    "with open(tokenizer, \"r\", encoding=\"latin-1\") as f:\n",
    "    tokens = f.readlines()\n",
    "\n",
    "with open(\"tokenizer_vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer가 tokenizer 파일 경로 문자열을 반환하여 실제 토크나이저를 로드해야 한다.\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "real_tokenizer = BertTokenizer(vocab_file=\"tokenizer_vocab.txt\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTDataset 클래스를 활용하여 tokenization, int encoding, padding 진행\n",
    "tok = real_tokenizer.tokenize\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, vocab, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, vocab, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch 형식의 데이터셋 만들어주기\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=2)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT 모델 구현하기\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT 모델 불러오기\n",
    "bertmodel = BERTClassifier(model,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in bertmodel.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in bertmodel.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 대표적인 loss func\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U jupyter jupyterlab notebook ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27560/1102525926.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56190b897421497cafb7888e92d40c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.7217010259628296 train acc 0.625\n",
      "epoch 1 train acc 0.7701990632318501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27560/1102525926.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f174e74e524408b055731184dae305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aa1eba818d48d78b559b100e068441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.3783543109893799 train acc 0.875\n",
      "epoch 2 train acc 0.8736826697892272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753e7102ebaf4f64b6044dc7b1355b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.890625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfe996ee3674675886e0e7c9dfa7f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.4088459014892578 train acc 0.875\n",
      "epoch 3 train acc 0.8849531615925058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02eb890af2f4177bdb5bbe98607568d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8828125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9756df8e70d945d9bfbf122c1c53e89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.3712441027164459 train acc 0.875\n",
      "epoch 4 train acc 0.887148711943794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782ab652e9b8470cba698553660ab404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8828125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f969e8fe86b4dfab97b82bbaa502021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.4244205355644226 train acc 0.875\n",
      "epoch 5 train acc 0.8953454332552694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0bd56627694345b19532cbfb17793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.88671875\n"
     ]
    }
   ],
   "source": [
    "# 학습 (Train)\n",
    "train_history=[]\n",
    "test_history=[]\n",
    "loss_history=[]\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    bertmodel.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = bertmodel(token_ids, valid_length, segment_ids)\n",
    "         \n",
    "        #print(label.shape,out.shape)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(bertmodel.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "            train_history.append(train_acc / (batch_id+1))\n",
    "            loss_history.append(loss.data.cpu().numpy())\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    #train_history.append(train_acc / (batch_id+1))\n",
    "    \n",
    "    bertmodel.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = bertmodel(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    test_history.append(test_acc / (batch_id+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 직접 입력하여 확인\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    test_data = [predict_sentence, '0']\n",
    "    dataset_another = [test_data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=2)\n",
    "    \n",
    "    bertmodel.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = bertmodel(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        test_eval = []\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"보이스피싱이 아닐 확률이 높습니다. 확률은 \")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"보이스피싱일 확률이 높습니다. 확률은 \")\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(out, dim=-1)\n",
    "        preds = torch.argmax(probs, dim=-1)\n",
    "        per = round(probs.tolist()[0][preds.item()] * 100,2)\n",
    "\n",
    "        print(\">> \" + test_eval[0] + str(per) + \"% 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 보이스피싱일 확률이 높습니다. 확률은 99.26% 입니다.\n"
     ]
    }
   ],
   "source": [
    "sentence = input(\"\")\n",
    "predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n본인께서 대가성의 돈을 받고 이 두 통장을 판매하신 계좌 양도 혐의의 가해자이신지, 그게 아니라면 본인이 본인도 모르게 \\n명의를 도용을 당하고... 자, 그러면 고객님. 고객님께서는 그럼 얼마까지 가능하신데요? 왜 무리라는 거죠? 제가 봤을 때는 \\n오히려 고객님한테 이득인데? 혹시라도 겁이 나서 은폐 또는 은닉을 하실 시에는 형법 155조 1-1항 증거인멸죄, 형법 152조 위증죄, \\n형법 132조 1항 공무집행방해죄가 추가된다는 점 명시를 해드리고...\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "본인께서 대가성의 돈을 받고 이 두 통장을 판매하신 계좌 양도 혐의의 가해자이신지, 그게 아니라면 본인이 본인도 모르게 \n",
    "명의를 도용을 당하고... 자, 그러면 고객님. 고객님께서는 그럼 얼마까지 가능하신데요? 왜 무리라는 거죠? 제가 봤을 때는 \n",
    "오히려 고객님한테 이득인데? 혹시라도 겁이 나서 은폐 또는 은닉을 하실 시에는 형법 155조 1-1항 증거인멸죄, 형법 152조 위증죄, \n",
    "형법 132조 1항 공무집행방해죄가 추가된다는 점 명시를 해드리고...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 (pkl 파일)\n",
    "torch.save(bertmodel, '/home/azureuser/Desktop/kr/kobert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오는 코드\n",
    "# 저장된 모델 불러오기\n",
    "# kobert = torch.load(\"kobert.pkl\")\n",
    "# kobert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
